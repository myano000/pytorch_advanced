{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.4 BERTを用いたレビュー文章に対する感情分析モデルの実装と学習・推論\n",
    "\n",
    "本ファイルでは、BERTを使用し、IMDbデータのポジ・ネガを分類するモデルを学習させ、推論します。また推論時のSelf-Attentionを可視化します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※　本章のファイルはすべてUbuntuでの動作を前提としています。Windowsなど文字コードが違う環境での動作にはご注意下さい。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.4 学習目標\n",
    "\n",
    "1.\tBERTのボキャブラリーをtorchtextで使用する実装方法を理解する\n",
    "2.\tBERTに分類タスク用のアダプターモジュールを追加し、感情分析を実施するモデルを実装できる\n",
    "3.\tBERTをファインチューニングして、モデルを学習できる\n",
    "4.  BERTのSelf-Attentionの重みを可視化し、推論の説明を試みることができる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前準備\n",
    "\n",
    "- 書籍の指示に従い、本章で使用するデータを用意します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDbデータを読み込み、DataLoaderを作成（BERTのTokenizerを使用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理と単語分割をまとめた関数を作成\n",
    "import re\n",
    "import string\n",
    "from utils.bert import BertTokenizer\n",
    "# フォルダ「utils」のbert.pyより\n",
    "\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    '''IMDbの前処理'''\n",
    "    # 改行コードを消去\n",
    "    text = re.sub('<br />', '', text)\n",
    "\n",
    "    # カンマ、ピリオド以外の記号をスペースに置換\n",
    "    for p in string.punctuation:\n",
    "        if (p == \".\") or (p == \",\"):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    # ピリオドなどの前後にはスペースを入れておく\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    return text\n",
    "\n",
    "\n",
    "# 単語分割用のTokenizerを用意\n",
    "tokenizer_bert = BertTokenizer(\n",
    "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
    "\n",
    "\n",
    "# 前処理と単語分割をまとめた関数を定義\n",
    "# 単語分割の関数を渡すので、tokenizer_bertではなく、tokenizer_bert.tokenizeを渡す点に注意\n",
    "def tokenizer_with_preprocessing(text, tokenizer=tokenizer_bert.tokenize):\n",
    "    text = preprocessing_text(text)\n",
    "    ret = tokenizer(text)  # tokenizer_bert\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
    "max_length = 256\n",
    "\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
    "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"[CLS]\", eos_token=\"[SEP]\", pad_token='[PAD]', unk_token='[UNK]')\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# (注釈)：各引数を再確認\n",
    "# sequential: データの長さが可変か？文章は長さがいろいろなのでTrue.ラベルはFalse\n",
    "# tokenize: 文章を読み込んだときに、前処理や単語分割をするための関数を定義\n",
    "# use_vocab：単語をボキャブラリーに追加するかどうか\n",
    "# lower：アルファベットがあったときに小文字に変換するかどうか\n",
    "# include_length: 文章の単語数のデータを保持するか\n",
    "# batch_first：ミニバッチの次元を先頭に用意するかどうか\n",
    "# fix_length：全部の文章を指定した長さと同じになるように、paddingします\n",
    "# init_token, eos_token, pad_token, unk_token：文頭、文末、padding、未知語に対して、どんな単語を与えるかを指定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォルダ「data」から各tsvファイルを読み込みます\n",
    "# BERT用で処理するので、10分弱時間がかかります\n",
    "train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/', train='IMDb_train.tsv',\n",
    "    test='IMDb_test.tsv', format='tsv',\n",
    "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
    "\n",
    "# torchtext.data.Datasetのsplit関数で訓練データとvalidationデータを分ける\n",
    "train_ds, val_ds = train_val_ds.split(\n",
    "    split_ratio=0.8, random_state=random.seed(1234))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTはBERTが持つ全単語でBertEmbeddingモジュールを作成しているので、ボキャブラリーとしては全単語を使用します\n",
    "# そのため訓練データからボキャブラリーは作成しません\n",
    "\n",
    "# まずBERT用の単語辞書を辞書型変数に用意します\n",
    "from utils.bert import BertTokenizer, load_vocab\n",
    "\n",
    "vocab_bert, ids_to_tokens_bert = load_vocab(\n",
    "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\")\n",
    "\n",
    "\n",
    "# このまま、TEXT.vocab.stoi= vocab_bert (stoiはstring_to_IDで、単語からIDへの辞書)としたいですが、\n",
    "# 一度bulild_vocabを実行しないとTEXTオブジェクトがvocabのメンバ変数をもってくれないです。\n",
    "# （'Field' object has no attribute 'vocab' というエラーをはきます）\n",
    "\n",
    "# 1度適当にbuild_vocabでボキャブラリーを作成してから、BERTのボキャブラリーを上書きします\n",
    "TEXT.build_vocab(train_ds, min_freq=1)\n",
    "TEXT.vocab.stoi = vocab_bert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
    "batch_size = 32  # BERTでは16、32あたりを使用する\n",
    "\n",
    "train_dl = torchtext.data.Iterator(\n",
    "    train_ds, batch_size=batch_size, train=True)\n",
    "\n",
    "val_dl = torchtext.data.Iterator(\n",
    "    val_ds, batch_size=batch_size, train=False, sort=False)\n",
    "\n",
    "test_dl = torchtext.data.Iterator(\n",
    "    test_ds, batch_size=batch_size, train=False, sort=False)\n",
    "\n",
    "# 辞書オブジェクトにまとめる\n",
    "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[  101,  1037,  2980,  ...,     0,     0,     0],\n",
      "        [  101,  7592,  1010,  ...,  6050,  2003,   102],\n",
      "        [  101,  1996,  3696,  ...,  9714,  8106,   102],\n",
      "        ...,\n",
      "        [  101,  5722,  1997,  ...,  2021,  2027,   102],\n",
      "        [  101,  2009, 20096,  ...,     0,     0,     0],\n",
      "        [  101,  2057,  2428,  ...,     0,     0,     0]]), tensor([125, 256, 256, 256, 197, 256, 256, 148, 256, 256, 199, 256, 256, 184,\n",
      "        232, 256, 256, 256,  75, 141, 165, 256, 139, 256, 182,  41,  64, 158,\n",
      "        256, 256, 107, 142]))\n",
      "tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# 動作確認 検証データのデータセットで確認\n",
    "batch = next(iter(val_dl))\n",
    "print(batch.Text)\n",
    "print(batch.Label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'hello', ',', 'i', 'was', 'alan', '##rick', '##mania', '##c', '.', 'i', 'm', 'a', 'still', 'crazy', 'ho', '##lic', '.', 'it', 'was', 'just', 'another', 'movie', 'i', 'watched', 'partly', 'on', 'tv', '.', 'then', 'i', 'had', 'to', 'get', 'the', 'video', 'tape', 'to', 'finally', 'find', 'out', 'how', 'it', 'ends', '.', 'then', 'i', 'wanted', 'the', 'dvd', ',', 'because', 'the', 'tape', 'showed', 'first', 'signs', 'of', 'decay', 'after', 'a', 'few', 'weeks', '.', 'after', 'the', 'dvd', 'i', 'had', 'to', 'lay', 'my', 'hands', 'on', 'the', 'soundtrack', '.', 'then', 'on', 'several', 'film', 'posters', 'and', 'the', 'film', 'script', '.', 'right', 'now', 'it', 'has', 'become', 'that', 'worse', 'that', 'i', 'try', 'to', 'push', 'other', 'people', 'into', 'addiction', 'with', 'my', 'website', 'and', 'still', 'crazy', 'parties', '.', 'how', 'could', 'that', 'happen', 'what', 'drove', 'me', 'into', 'addiction', 'ok', ',', 'it', 's', 'one', 'of', 'those', 'funny', 'but', 'somehow', 'sad', 'and', 'mel', '##an', '##cho', '##lic', 'intelligent', 'comedies', 'like', 'only', 'the', 'british', 'can', 'produce', '.', 'alright', ',', 'the', 'movie', 'is', 'worlds', 'apart', 'from', 'stuff', 'like', 'this', 'is', 'spinal', 'tap', ',', 'because', 'of', 'the', 'characters', ',', 'that', 'aren', 't', 'childish', 'or', 'ultra', 'cool', ',', 'but', 'real', '.', 'this', 'is', 'a', 'story', 'about', 'men', 'getting', 'older', ',', 'too', '.', 'a', 'story', 'about', 'men', 'getting', 'along', 'with', 'each', 'other', '.', 'or', 'don', 't', '.', 'it', 'contains', 'some', 'of', 'the', 'best', 'actors', 'possible', '.', 'tim', 'spa', '##ll', '.', 'stephen', 're', '##a', '.', 'bruce', 'robinson', '.', 'jimmy', 'nail', '.', 'and', 'bill', 'ni', '##gh', '##y', '.', 'bill', 'ni', '##gh', '##y', 'who', 'puts', 'on', 'one', 'of', 'the', 'best', 'performances', 'i', 've', 'ever', 'seen', 'in', 'a', 'film', '.', 'good', ',', 'the', 'soundtrack', 'is', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# ミニバッチの1文目を確認してみる\n",
    "text_minibatch_1 = (batch.Text[0][1]).numpy()\n",
    "\n",
    "# IDを単語に戻す\n",
    "text = tokenizer_bert.convert_ids_to_tokens(text_minibatch_1)\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 感情分析用のBERTモデルを構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\n",
      "bert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\n",
      "bert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\n",
      "bert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\n",
      "bert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\n",
      "bert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\n",
      "bert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\n",
      "bert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\n",
      "bert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\n",
      "bert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\n",
      "bert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\n",
      "bert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\n",
      "bert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\n",
      "bert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\n",
      "bert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\n",
      "bert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\n",
      "bert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\n",
      "bert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\n",
      "bert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\n",
      "bert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\n",
      "bert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\n",
      "bert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\n",
      "bert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\n",
      "bert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\n",
      "bert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\n",
      "bert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\n",
      "bert.pooler.dense.weight→pooler.dense.weight\n",
      "bert.pooler.dense.bias→pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "from utils.bert import get_config, BertModel, set_learned_params\n",
    "\n",
    "# モデル設定のJOSNファイルをオブジェクト変数として読み込みます\n",
    "config = get_config(file_path=\"./weights/bert_config.json\")\n",
    "\n",
    "# BERTモデルを作成します\n",
    "net_bert = BertModel(config)\n",
    "\n",
    "# BERTモデルに学習済みパラメータセットします\n",
    "net_bert = set_learned_params(\n",
    "    net_bert, weights_path=\"./weights/pytorch_model.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForIMDb(nn.Module):\n",
    "    '''BERTモデルにIMDbのポジ・ネガを判定する部分をつなげたモデル'''\n",
    "\n",
    "    def __init__(self, net_bert):\n",
    "        super(BertForIMDb, self).__init__()\n",
    "\n",
    "        # BERTモジュール\n",
    "        self.bert = net_bert  # BERTモデル\n",
    "\n",
    "        # headにポジネガ予測を追加\n",
    "        # 入力はBERTの出力特徴量の次元、出力はポジ・ネガの2つ\n",
    "        self.cls = nn.Linear(in_features=768, out_features=2)\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.cls.weight, std=0.02)\n",
    "        nn.init.normal_(self.cls.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=False, attention_show_flg=False):\n",
    "        '''\n",
    "        input_ids： [batch_size, sequence_length]の文章の単語IDの羅列\n",
    "        token_type_ids： [batch_size, sequence_length]の、各単語が1文目なのか、2文目なのかを示すid\n",
    "        attention_mask：Transformerのマスクと同じ働きのマスキングです\n",
    "        output_all_encoded_layers：最終出力に12段のTransformerの全部をリストで返すか、最後だけかを指定\n",
    "        attention_show_flg：Self-Attentionの重みを返すかのフラグ\n",
    "        '''\n",
    "\n",
    "        # BERTの基本モデル部分の順伝搬\n",
    "        # 順伝搬させる\n",
    "        if attention_show_flg == True:\n",
    "            '''attention_showのときは、attention_probsもリターンする'''\n",
    "            encoded_layers, pooled_output, attention_probs = self.bert(\n",
    "                input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg)\n",
    "        elif attention_show_flg == False:\n",
    "            encoded_layers, pooled_output = self.bert(\n",
    "                input_ids, token_type_ids, attention_mask, output_all_encoded_layers, attention_show_flg)\n",
    "\n",
    "        # 入力文章の1単語目[CLS]の特徴量を使用して、ポジ・ネガを分類します\n",
    "        vec_0 = encoded_layers[:, 0, :]\n",
    "        vec_0 = vec_0.view(-1, 768)  # sizeを[batch_size, hidden_sizeに変換\n",
    "        out = self.cls(vec_0)\n",
    "\n",
    "        # attention_showのときは、attention_probs（1番最後の）もリターンする\n",
    "        if attention_show_flg == True:\n",
    "            return out, attention_probs\n",
    "        elif attention_show_flg == False:\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク設定完了\n"
     ]
    }
   ],
   "source": [
    "# モデル構築\n",
    "net = BertForIMDb(net_bert)\n",
    "\n",
    "# 訓練モードに設定\n",
    "net.train()\n",
    "\n",
    "print('ネットワーク設定完了')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTのファインチューニングに向けた設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配計算を最後のBertLayerモジュールと追加した分類アダプターのみ実行\n",
    "\n",
    "# 1. まず全部を、勾配計算Falseにしてしまう\n",
    "for name, param in net.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. 最後のBertLayerモジュールを勾配計算ありに変更\n",
    "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 3. 識別器を勾配計算ありに変更\n",
    "for name, param in net.cls.named_parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法の設定\n",
    "\n",
    "# BERTの元の部分はファインチューニング\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
    "    {'params': net.cls.parameters(), 'lr': 5e-5}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習・検証を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "use_amp = True\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "device_amp = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # ミニバッチのサイズ\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "            iteration = 1\n",
    "\n",
    "            # 開始時刻を保存\n",
    "            t_epoch_start = time.time()\n",
    "            t_iter_start = time.time()\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書型変数\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch.Text[0].to(device)  # 文章\n",
    "                labels = batch.Label.to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with torch.autocast(device_type=device_amp, dtype=torch.float16, enabled=use_amp):\n",
    "                        #autocastで9分から5分へ44%短縮。正解率は、0.9034から0.9059でほぼ変化なし\n",
    "\n",
    "                        # BertForIMDbに入力\n",
    "                        outputs = net(inputs, token_type_ids=None, attention_mask=None,\n",
    "                                    output_all_encoded_layers=False, attention_show_flg=False)\n",
    "\n",
    "                        loss = criterion(outputs, labels)  # 損失を計算\n",
    "\n",
    "                        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "                        # 訓練時はバックプロパゲーション\n",
    "                        if phase == 'train':\n",
    "                            #loss.backward()\n",
    "                            #optimizer.step()\n",
    "                            scaler.scale(loss).backward()\n",
    "                            # Unscales the gradients of optimizer's assigned params in-place\n",
    "                            # https://pytorch.org/docs/stable/notes/amp_examples.html\n",
    "                            # https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html\n",
    "                            scaler.unscale_(optimizer)\n",
    "\n",
    "                            # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n",
    "                            torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.1)\n",
    "\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "\n",
    "                            if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
    "                                t_iter_finish = time.time()\n",
    "                                duration = t_iter_finish - t_iter_start\n",
    "                                acc = (torch.sum(preds == labels.data)\n",
    "                                    ).double()/batch_size\n",
    "                                print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec. || 本イテレーションの正解率：{}'.format(\n",
    "                                    iteration, loss.item(), duration, acc))\n",
    "                                t_iter_start = time.time()\n",
    "\n",
    "                        iteration += 1\n",
    "\n",
    "                        # 損失と正解数の合計を更新\n",
    "                        epoch_loss += loss.item() * batch_size\n",
    "                        epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            t_epoch_finish = time.time()\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double(\n",
    "            ) / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "            t_epoch_start = time.time()\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:0\n",
      "-----start-------\n",
      "イテレーション 10 || Loss: 0.1135 || 10iter: 2.4682 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 20 || Loss: 0.2421 || 10iter: 2.1526 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 30 || Loss: 0.1653 || 10iter: 2.1773 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 40 || Loss: 0.5237 || 10iter: 2.1605 sec. || 本イテレーションの正解率：0.8125\n",
      "イテレーション 50 || Loss: 0.2492 || 10iter: 2.1584 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 60 || Loss: 0.1791 || 10iter: 2.1607 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 70 || Loss: 0.3931 || 10iter: 2.1678 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 80 || Loss: 0.1554 || 10iter: 2.1571 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 90 || Loss: 0.1028 || 10iter: 2.0984 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 100 || Loss: 0.2302 || 10iter: 2.1327 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 110 || Loss: 0.2842 || 10iter: 2.1200 sec. || 本イテレーションの正解率：0.8125\n",
      "イテレーション 120 || Loss: 0.3017 || 10iter: 2.1404 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 130 || Loss: 0.1221 || 10iter: 2.1485 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 140 || Loss: 0.1155 || 10iter: 2.1446 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 150 || Loss: 0.0631 || 10iter: 2.1681 sec. || 本イテレーションの正解率：1.0\n",
      "イテレーション 160 || Loss: 0.1550 || 10iter: 2.1596 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 170 || Loss: 0.3580 || 10iter: 2.1656 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 180 || Loss: 0.1248 || 10iter: 2.1830 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 190 || Loss: 0.1937 || 10iter: 2.1695 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 200 || Loss: 0.2054 || 10iter: 2.1777 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 210 || Loss: 0.3136 || 10iter: 2.1713 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 220 || Loss: 0.1199 || 10iter: 2.1751 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 230 || Loss: 0.1789 || 10iter: 2.1456 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 240 || Loss: 0.3837 || 10iter: 2.1062 sec. || 本イテレーションの正解率：0.78125\n",
      "イテレーション 250 || Loss: 0.1198 || 10iter: 2.1191 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 260 || Loss: 0.0850 || 10iter: 2.1241 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 270 || Loss: 0.2367 || 10iter: 2.1449 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 280 || Loss: 0.2413 || 10iter: 2.1494 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 290 || Loss: 0.1960 || 10iter: 2.1580 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 300 || Loss: 0.1335 || 10iter: 2.1657 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 310 || Loss: 0.2322 || 10iter: 2.1729 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 320 || Loss: 0.1915 || 10iter: 2.1799 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 330 || Loss: 0.1585 || 10iter: 2.1601 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 340 || Loss: 0.2574 || 10iter: 2.1631 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 350 || Loss: 0.1670 || 10iter: 2.1628 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 360 || Loss: 0.1649 || 10iter: 2.1642 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 370 || Loss: 0.2681 || 10iter: 2.1622 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 380 || Loss: 0.0685 || 10iter: 2.1727 sec. || 本イテレーションの正解率：1.0\n",
      "イテレーション 390 || Loss: 0.1400 || 10iter: 2.0918 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 400 || Loss: 0.0541 || 10iter: 2.1201 sec. || 本イテレーションの正解率：1.0\n",
      "イテレーション 410 || Loss: 0.2715 || 10iter: 2.1218 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 420 || Loss: 0.1527 || 10iter: 2.1355 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 430 || Loss: 0.2842 || 10iter: 2.1400 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 440 || Loss: 0.2885 || 10iter: 2.1537 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 450 || Loss: 0.2683 || 10iter: 2.1529 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 460 || Loss: 0.1691 || 10iter: 2.1548 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 470 || Loss: 0.1622 || 10iter: 2.1677 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 480 || Loss: 0.1410 || 10iter: 2.1618 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 490 || Loss: 0.1013 || 10iter: 2.1923 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 500 || Loss: 0.3166 || 10iter: 2.1677 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 510 || Loss: 0.1159 || 10iter: 2.1739 sec. || 本イテレーションの正解率：1.0\n",
      "イテレーション 520 || Loss: 0.3752 || 10iter: 2.1674 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 530 || Loss: 0.0634 || 10iter: 2.1549 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 540 || Loss: 0.1464 || 10iter: 2.0928 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 550 || Loss: 0.1783 || 10iter: 2.1097 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 560 || Loss: 0.4145 || 10iter: 2.1260 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 570 || Loss: 0.2847 || 10iter: 2.1402 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 580 || Loss: 0.2393 || 10iter: 2.1500 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 590 || Loss: 0.0632 || 10iter: 2.1509 sec. || 本イテレーションの正解率：1.0\n",
      "イテレーション 600 || Loss: 0.3072 || 10iter: 2.1624 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 610 || Loss: 0.3145 || 10iter: 2.1670 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 620 || Loss: 0.3803 || 10iter: 2.1684 sec. || 本イテレーションの正解率：0.84375\n",
      "Epoch 1/2 | train |  Loss: 0.2148 Acc: 0.9136\n",
      "Epoch 1/2 |  val  |  Loss: 0.2472 Acc: 0.9022\n",
      "イテレーション 10 || Loss: 0.3214 || 10iter: 2.1693 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 20 || Loss: 0.2089 || 10iter: 2.1701 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 30 || Loss: 0.1804 || 10iter: 2.1716 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 40 || Loss: 0.1845 || 10iter: 2.1650 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 50 || Loss: 0.0856 || 10iter: 2.1652 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 60 || Loss: 0.3960 || 10iter: 2.1658 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 70 || Loss: 0.1731 || 10iter: 2.1666 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 80 || Loss: 0.2847 || 10iter: 2.1571 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 90 || Loss: 0.1862 || 10iter: 2.1009 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 100 || Loss: 0.1333 || 10iter: 2.1149 sec. || 本イテレーションの正解率：1.0\n",
      "イテレーション 110 || Loss: 0.1078 || 10iter: 2.1373 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 120 || Loss: 0.2697 || 10iter: 2.1357 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 130 || Loss: 0.1257 || 10iter: 2.1439 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 140 || Loss: 0.0784 || 10iter: 2.1800 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 150 || Loss: 0.0774 || 10iter: 2.1532 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 160 || Loss: 0.3306 || 10iter: 2.1633 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 170 || Loss: 0.1715 || 10iter: 2.1660 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 180 || Loss: 0.1668 || 10iter: 2.1791 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 190 || Loss: 0.2869 || 10iter: 2.1656 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 200 || Loss: 0.2947 || 10iter: 2.1639 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 210 || Loss: 0.1190 || 10iter: 2.1655 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 220 || Loss: 0.3341 || 10iter: 2.1648 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 230 || Loss: 0.0951 || 10iter: 2.1768 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 240 || Loss: 0.4234 || 10iter: 2.1139 sec. || 本イテレーションの正解率：0.78125\n",
      "イテレーション 250 || Loss: 0.4511 || 10iter: 2.1164 sec. || 本イテレーションの正解率：0.8125\n",
      "イテレーション 260 || Loss: 0.1521 || 10iter: 2.1232 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 270 || Loss: 0.1796 || 10iter: 2.1323 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 280 || Loss: 0.1158 || 10iter: 2.1436 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 290 || Loss: 0.1735 || 10iter: 2.1573 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 300 || Loss: 0.2029 || 10iter: 2.1552 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 310 || Loss: 0.0837 || 10iter: 2.1663 sec. || 本イテレーションの正解率：1.0\n",
      "イテレーション 320 || Loss: 0.1822 || 10iter: 2.2926 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 330 || Loss: 0.1776 || 10iter: 2.2002 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 340 || Loss: 0.1785 || 10iter: 2.1745 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 350 || Loss: 0.2704 || 10iter: 2.1782 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 360 || Loss: 0.1943 || 10iter: 2.1740 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 370 || Loss: 0.3325 || 10iter: 2.1854 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 380 || Loss: 0.3522 || 10iter: 2.1703 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 390 || Loss: 0.2558 || 10iter: 2.0976 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 400 || Loss: 0.2555 || 10iter: 2.1185 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 410 || Loss: 0.3514 || 10iter: 2.1314 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 420 || Loss: 0.2957 || 10iter: 2.1419 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 430 || Loss: 0.1925 || 10iter: 2.1490 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 440 || Loss: 0.2291 || 10iter: 2.1697 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 450 || Loss: 0.4229 || 10iter: 2.1598 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 460 || Loss: 0.1910 || 10iter: 2.1728 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 470 || Loss: 0.2142 || 10iter: 2.1678 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 480 || Loss: 0.1308 || 10iter: 2.1864 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 490 || Loss: 0.3228 || 10iter: 2.1712 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 500 || Loss: 0.1950 || 10iter: 2.1710 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 510 || Loss: 0.2444 || 10iter: 2.1884 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 520 || Loss: 0.3582 || 10iter: 2.1829 sec. || 本イテレーションの正解率：0.84375\n",
      "イテレーション 530 || Loss: 0.2561 || 10iter: 2.1680 sec. || 本イテレーションの正解率：0.875\n",
      "イテレーション 540 || Loss: 0.2724 || 10iter: 2.1175 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 550 || Loss: 0.1729 || 10iter: 2.1258 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 560 || Loss: 0.2425 || 10iter: 2.1426 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 570 || Loss: 0.2820 || 10iter: 2.1477 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 580 || Loss: 0.1055 || 10iter: 2.1628 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 590 || Loss: 0.1666 || 10iter: 2.1755 sec. || 本イテレーションの正解率：0.90625\n",
      "イテレーション 600 || Loss: 0.1933 || 10iter: 2.1738 sec. || 本イテレーションの正解率：0.96875\n",
      "イテレーション 610 || Loss: 0.2397 || 10iter: 2.1678 sec. || 本イテレーションの正解率：0.9375\n",
      "イテレーション 620 || Loss: 0.2447 || 10iter: 2.1689 sec. || 本イテレーションの正解率：0.90625\n",
      "Epoch 2/2 | train |  Loss: 0.2134 Acc: 0.9163\n",
      "Epoch 2/2 |  val  |  Loss: 0.2470 Acc: 0.9048\n"
     ]
    }
   ],
   "source": [
    "# 学習・検証を実行する。1epochに20分ほどかかります\n",
    "num_epochs = 2\n",
    "net_trained = train_model(net, dataloaders_dict,\n",
    "                          criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習したネットワークパラメータを保存します\n",
    "save_path = './weights/bert_fine_tuning_IMDb_amp.pth'\n",
    "torch.save(net_trained.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [02:09<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータ25000個での正解率：0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# テストデータでの正解率を求める\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained.eval()   # モデルを検証モードに\n",
    "net_trained.to(device)  # GPUが使えるならGPUへ送る\n",
    "\n",
    "# epochの正解数を記録する変数\n",
    "epoch_corrects = 0\n",
    "\n",
    "for batch in tqdm(test_dl):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = batch.Text[0].to(device)  # 文章\n",
    "    labels = batch.Label.to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "        with torch.autocast(device_type=device_amp, dtype=torch.float16, enabled=use_amp):\n",
    "            # ampで4分が2分に短縮。正解率も0.901以下した変わらない\n",
    "            # BertForIMDbに入力\n",
    "            outputs = net_trained(inputs, token_type_ids=None, attention_mask=None,\n",
    "                                output_all_encoded_layers=False, attention_show_flg=False)\n",
    "\n",
    "            loss = criterion(outputs, labels)  # 損失を計算\n",
    "            \n",
    "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "        epoch_corrects += torch.sum(preds == labels.data)  # 正解数の合計を更新\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dl.dataset), epoch_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentionの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchtext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# batch_sizeを64にしたテストデータでDataLoaderを作成\u001b[39;00m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 3\u001b[0m test_dl \u001b[38;5;241m=\u001b[39m \u001b[43mtorchtext\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator(\n\u001b[1;32m      4\u001b[0m     test_ds, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchtext' is not defined"
     ]
    }
   ],
   "source": [
    "# batch_sizeを64にしたテストデータでDataLoaderを作成\n",
    "batch_size = 64\n",
    "test_dl = torchtext.data.Iterator(\n",
    "    test_ds, batch_size=batch_size, train=False, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# BertForIMDbで処理\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ミニバッチの用意\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtest_dl\u001b[49m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# GPUが使えるならGPUにデータを送る\u001b[39;00m\n\u001b[1;32m      7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mText[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# 文章\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dl' is not defined"
     ]
    }
   ],
   "source": [
    "# BertForIMDbで処理\n",
    "\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(test_dl))\n",
    "\n",
    "# GPUが使えるならGPUにデータを送る\n",
    "inputs = batch.Text[0].to(device)  # 文章\n",
    "labels = batch.Label.to(device)  # ラベル\n",
    "\n",
    "outputs, attention_probs = net_trained(inputs, token_type_ids=None, attention_mask=None,\n",
    "                                       output_all_encoded_layers=False, attention_show_flg=True)\n",
    "\n",
    "_, preds = torch.max(outputs, 1)  # ラベルを予測\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLを作成する関数を実装\n",
    "\n",
    "\n",
    "def highlight(word, attn):\n",
    "    \"Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\"\n",
    "\n",
    "    html_color = '#%02X%02X%02X' % (\n",
    "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
    "\n",
    "\n",
    "def mk_html(index, batch, preds, normlized_weights, TEXT):\n",
    "    \"HTMLデータを作成する\"\n",
    "\n",
    "    # indexの結果を抽出\n",
    "    sentence = batch.Text[0][index]  # 文章\n",
    "    label = batch.Label[index]  # ラベル\n",
    "    pred = preds[index]  # 予測\n",
    "\n",
    "    # ラベルと予測結果を文字に置き換え\n",
    "    if label == 0:\n",
    "        label_str = \"Negative\"\n",
    "    else:\n",
    "        label_str = \"Positive\"\n",
    "\n",
    "    if pred == 0:\n",
    "        pred_str = \"Negative\"\n",
    "    else:\n",
    "        pred_str = \"Positive\"\n",
    "\n",
    "    # 表示用のHTMLを作成する\n",
    "    html = '正解ラベル：{}<br>推論ラベル：{}<br><br>'.format(label_str, pred_str)\n",
    "\n",
    "    # Self-Attentionの重みを可視化。Multi-Headが12個なので、12種類のアテンションが存在\n",
    "    for i in range(12):\n",
    "\n",
    "        # indexのAttentionを抽出と規格化\n",
    "        # 0単語目[CLS]の、i番目のMulti-Head Attentionを取り出す\n",
    "        # indexはミニバッチの何個目のデータかをしめす\n",
    "        attens = normlized_weights[index, i, 0, :]\n",
    "        attens /= attens.max()\n",
    "\n",
    "        html += '[BERTのAttentionを可視化_' + str(i+1) + ']<br>'\n",
    "        for word, attn in zip(sentence, attens):\n",
    "\n",
    "            # 単語が[SEP]の場合は文章が終わりなのでbreak\n",
    "            if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
    "                break\n",
    "\n",
    "            # 関数highlightで色をつける、関数tokenizer_bert.convert_ids_to_tokensでIDを単語に戻す\n",
    "            html += highlight(tokenizer_bert.convert_ids_to_tokens(\n",
    "                [word.numpy().tolist()])[0], attn)\n",
    "        html += \"<br><br>\"\n",
    "\n",
    "    # 12種類のAttentionの平均を求める。最大値で規格化\n",
    "    all_attens = attens*0  # all_attensという変数を作成する\n",
    "    for i in range(12):\n",
    "        attens += normlized_weights[index, i, 0, :]\n",
    "    attens /= attens.max()\n",
    "\n",
    "    html += '[BERTのAttentionを可視化_ALL]<br>'\n",
    "    for word, attn in zip(sentence, attens):\n",
    "\n",
    "        # 単語が[SEP]の場合は文章が終わりなのでbreak\n",
    "        if tokenizer_bert.convert_ids_to_tokens([word.numpy().tolist()])[0] == \"[SEP]\":\n",
    "            break\n",
    "\n",
    "        # 関数highlightで色をつける、関数tokenizer_bert.convert_ids_to_tokensでIDを単語に戻す\n",
    "        html += highlight(tokenizer_bert.convert_ids_to_tokens(\n",
    "            [word.numpy().tolist()])[0], attn)\n",
    "    html += \"<br><br>\"\n",
    "\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML\n\u001b[1;32m      3\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# 出力させたいデータ\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m html_output \u001b[38;5;241m=\u001b[39m mk_html(index, \u001b[43mbatch\u001b[49m, preds, attention_probs, TEXT)  \u001b[38;5;66;03m# HTML作成\u001b[39;00m\n\u001b[1;32m      5\u001b[0m HTML(html_output)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "index = 3  # 出力させたいデータ\n",
    "html_output = mk_html(index, batch, preds, attention_probs, TEXT)  # HTML作成\n",
    "HTML(html_output)  # HTML形式で出力\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m61\u001b[39m  \u001b[38;5;66;03m# 出力させたいデータ\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m html_output \u001b[38;5;241m=\u001b[39m mk_html(index, \u001b[43mbatch\u001b[49m, preds, attention_probs, TEXT)  \u001b[38;5;66;03m# HTML作成\u001b[39;00m\n\u001b[1;32m      3\u001b[0m HTML(html_output)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "index = 61  # 出力させたいデータ\n",
    "html_output = mk_html(index, batch, preds, attention_probs, TEXT)  # HTML作成\n",
    "HTML(html_output)  # HTML形式で出力\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
