{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYtEkX621-OC"
      },
      "source": [
        "# 4.6 学習と検証の実施\n",
        "\n",
        "- 本ファイルでは、OpenPoseの学習と検証の実施を行います。AWSのGPUマシンで計算します。\n",
        "- p2.xlargeで45分ほどかかります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZtHjCjD1-OH"
      },
      "source": [
        "# 学習目標\n",
        "\n",
        "1.\tOpenPoseの学習を実装できるようになる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAm0G0mW1-OI"
      },
      "source": [
        "# 事前準備\n",
        "\n",
        "- これまでの章で実装したクラスと関数をフォルダ「utils」内に用意しています\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X7WUHRm71-OJ"
      },
      "outputs": [],
      "source": [
        "# パッケージのimport\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UhDCLEgj1-OK"
      },
      "outputs": [],
      "source": [
        "# 初期設定\n",
        "# Setup seeds\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utz_Cyy21-OL"
      },
      "source": [
        "# DataLoader作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OvEffoMb1-OL"
      },
      "outputs": [],
      "source": [
        "from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n",
        "\n",
        "# MS COCOのファイルパスリスト作成\n",
        "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(\n",
        "    rootpath=\"./data/\")\n",
        "\n",
        "# Dataset作成\n",
        "# 本書ではデータ量の問題から、trainをval_listで作成している点に注意\n",
        "train_dataset = COCOkeypointsDataset(\n",
        "    val_img_list, val_mask_list, val_meta_list, phase=\"train\", transform=DataTransform())\n",
        "\n",
        "# 今回は簡易な学習とし検証データは作成しない\n",
        "# val_dataset = CocokeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase=\"val\", transform=DataTransform())\n",
        "\n",
        "# DataLoader作成\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# val_dataloader = data.DataLoader(\n",
        "#    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書型変数にまとめる\n",
        "# dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": None}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g53aOeuY1-ON"
      },
      "source": [
        "# ネットワークモデル作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oh1g-qsZ1-OO"
      },
      "outputs": [],
      "source": [
        "from utils.openpose_net import OpenPoseNet\n",
        "net = OpenPoseNet()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iehMlbZl1-OQ"
      },
      "source": [
        "# 損失関数を定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5cy4COD81-OQ"
      },
      "outputs": [],
      "source": [
        "# 損失関数の設定\n",
        "class OpenPoseLoss(nn.Module):\n",
        "    \"\"\"OpenPoseの損失関数のクラスです。\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(OpenPoseLoss, self).__init__()\n",
        "\n",
        "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
        "        \"\"\"\n",
        "        損失関数の計算。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        saved_for_loss : OpenPoseNetの出力(リスト)\n",
        "\n",
        "        heatmap_target : [num_batch, 19, 46, 46]\n",
        "            正解の部位のアノテーション情報\n",
        "\n",
        "        heatmap_mask : [num_batch, 19, 46, 46]\n",
        "            heatmap画像のmask\n",
        "\n",
        "        paf_target : [num_batch, 38, 46, 46]\n",
        "            正解のPAFのアノテーション情報\n",
        "\n",
        "        paf_mask : [num_batch, 38, 46, 46]\n",
        "            PAF画像のmask\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : テンソル\n",
        "            損失の値\n",
        "        \"\"\"\n",
        "\n",
        "        total_loss = 0\n",
        "        # ステージごとに計算します\n",
        "        for j in range(6):\n",
        "\n",
        "            # PAFsとheatmapsにおいて、マスクされている部分（paf_mask=0など）は無視させる\n",
        "            # PAFs\n",
        "            pred1 = saved_for_loss[2 * j] * paf_mask\n",
        "            gt1 = paf_target.float() * paf_mask\n",
        "\n",
        "            # heatmaps\n",
        "            pred2 = saved_for_loss[2 * j + 1] * heat_mask\n",
        "            gt2 = heatmap_target.float()*heat_mask\n",
        "\n",
        "            total_loss += F.mse_loss(pred1, gt1, reduction='mean') + \\\n",
        "                F.mse_loss(pred2, gt2, reduction='mean')\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "criterion = OpenPoseLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWDPFIh-1-OR"
      },
      "source": [
        "# 最適化手法を設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7dWlCWqG1-OR"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=1e-2,\n",
        "                      momentum=0.9,\n",
        "                      weight_decay=0.0001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNgpvEju1-OS"
      },
      "source": [
        "# 学習を実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6acs014S1-OS"
      },
      "outputs": [],
      "source": [
        "# モデルを学習させる関数を作成\n",
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "device_amp = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.cuda.empty_cache\n",
        "\n",
        "    # 画像の枚数\n",
        "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
        "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "\n",
        "    # イテレーションカウンタをセット\n",
        "    iteration = 1\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        torch.cuda.empty_cache\n",
        "\n",
        "        # 開始時刻を保存\n",
        "        t_epoch_start = time.time()\n",
        "        t_iter_start = time.time()\n",
        "        epoch_train_loss = 0.0  # epochの損失和\n",
        "        epoch_val_loss = 0.0  # epochの損失和\n",
        "\n",
        "        print('-------------')\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "                optimizer.zero_grad()\n",
        "                print('（train）')\n",
        "\n",
        "            # 今回は検証はスキップ\n",
        "            else:\n",
        "                continue\n",
        "                # net.eval()   # モデルを検証モードに\n",
        "                # print('-------------')\n",
        "                # print('（val）')\n",
        "\n",
        "            # データローダーからminibatchずつ取り出すループ\n",
        "            for imges, heatmap_target, heat_mask, paf_target, paf_mask in tqdm(dataloaders_dict[phase]):\n",
        "                # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
        "                # issue #186より不要なのでコメントアウト\n",
        "                # if imges.size()[0] == 1:\n",
        "                #     continue\n",
        "                torch.cuda.empty_cache\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                imges = imges.to(device)\n",
        "                heatmap_target = heatmap_target.to(device)\n",
        "                heat_mask = heat_mask.to(device)\n",
        "                paf_target = paf_target.to(device)\n",
        "                paf_mask = paf_mask.to(device)\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    with torch.autocast(device_type=device_amp, dtype=torch.float16, enabled=use_amp):\n",
        "                        \n",
        "                        # (out6_1, out6_2)は使わないので _ で代替\n",
        "                        _, saved_for_loss = net(imges)\n",
        "\n",
        "                        loss = criterion(saved_for_loss, heatmap_target,\n",
        "                                        heat_mask, paf_target, paf_mask)\n",
        "                        del saved_for_loss\n",
        "                        # 訓練時はバックプロパゲーション\n",
        "                        if phase == 'train':\n",
        "                            scaler.scale(loss).backward()\n",
        "                            scaler.step(optimizer)\n",
        "                            scaler.update()\n",
        "                            #optimizer.zero_grad()\n",
        "                            #loss.backward()\n",
        "                            #optimizer.step()\n",
        "\n",
        "                            if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
        "                                t_iter_finish = time.time()\n",
        "                                duration = t_iter_finish - t_iter_start\n",
        "                                print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
        "                                    iteration, loss.item()/batch_size, duration))\n",
        "                                t_iter_start = time.time()\n",
        "\n",
        "                            epoch_train_loss += loss.item()\n",
        "                            iteration += 1\n",
        "\n",
        "                        # 検証時\n",
        "                        # else:\n",
        "                            #epoch_val_loss += loss.item()\n",
        "\n",
        "        # epochのphaseごとのlossと正解率\n",
        "        t_epoch_finish = time.time()\n",
        "        print('-------------')\n",
        "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
        "            epoch+1, epoch_train_loss/num_train_imgs, 0))\n",
        "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "    # 最後のネットワークを保存する\n",
        "    torch.save(net.state_dict(), 'weights/openpose_net_' +\n",
        "               str(epoch+1) + '.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KDz3LPQr1-OT",
        "outputId": "92e793d1-5755-4e0f-cd91-8a2ea68e4ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "-------------\n",
            "Epoch 1/2\n",
            "-------------\n",
            "（train）\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 10/153 [03:53<52:19, 21.95s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 10 || Loss: 0.0093 || 10iter: 233.3719 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 20/153 [07:52<50:53, 22.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 20 || Loss: 0.0082 || 10iter: 239.1212 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 30/153 [11:22<39:18, 19.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 30 || Loss: 0.0068 || 10iter: 209.5169 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 40/153 [15:26<48:08, 25.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 40 || Loss: 0.0057 || 10iter: 244.5800 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 50/153 [18:06<24:29, 14.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 50 || Loss: 0.0048 || 10iter: 159.8140 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 60/153 [21:20<37:22, 24.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 60 || Loss: 0.0044 || 10iter: 194.1606 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 70/153 [25:00<31:09, 22.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 70 || Loss: 0.0037 || 10iter: 220.1528 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 80/153 [28:40<27:12, 22.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 80 || Loss: 0.0030 || 10iter: 219.6714 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 90/153 [32:19<23:23, 22.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 90 || Loss: 0.0027 || 10iter: 219.0387 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 100/153 [35:58<19:32, 22.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 100 || Loss: 0.0026 || 10iter: 219.0055 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 110/153 [39:37<15:50, 22.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 110 || Loss: 0.0021 || 10iter: 218.5740 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 120/153 [43:13<12:05, 22.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 120 || Loss: 0.0022 || 10iter: 215.9370 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 130/153 [46:49<08:25, 21.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 130 || Loss: 0.0020 || 10iter: 215.9405 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 140/153 [50:24<04:46, 22.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 140 || Loss: 0.0018 || 10iter: 215.6495 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 150/153 [54:00<01:05, 21.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 150 || Loss: 0.0019 || 10iter: 215.8314 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 153/153 [54:47<00:00, 21.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------\n",
            "epoch 1 || Epoch_TRAIN_Loss:0.0043 ||Epoch_VAL_Loss:0.0000\n",
            "timer:  3287.8577 sec.\n",
            "-------------\n",
            "Epoch 2/2\n",
            "-------------\n",
            "（train）\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 7/153 [03:33<1:13:49, 30.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 160 || Loss: 0.0017 || 10iter: 213.9562 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 17/153 [09:26<1:17:23, 34.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 170 || Loss: 0.0016 || 10iter: 352.8719 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 27/153 [15:24<1:15:11, 35.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 180 || Loss: 0.0020 || 10iter: 357.7026 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 37/153 [21:12<1:04:49, 33.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 190 || Loss: 0.0016 || 10iter: 347.9576 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 47/153 [27:01<59:46, 33.83s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 200 || Loss: 0.0016 || 10iter: 349.4240 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 57/153 [32:37<55:03, 34.41s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 210 || Loss: 0.0014 || 10iter: 335.5409 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 67/153 [38:26<53:07, 37.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 220 || Loss: 0.0017 || 10iter: 348.4736 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 77/153 [44:06<43:38, 34.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 230 || Loss: 0.0013 || 10iter: 340.4400 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 87/153 [50:02<37:34, 34.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 240 || Loss: 0.0013 || 10iter: 355.9396 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 97/153 [56:05<33:28, 35.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 250 || Loss: 0.0015 || 10iter: 363.1793 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 107/153 [1:01:36<25:29, 33.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 260 || Loss: 0.0013 || 10iter: 331.2767 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 117/153 [1:07:04<18:37, 31.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 270 || Loss: 0.0016 || 10iter: 327.8008 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 127/153 [1:12:57<14:47, 34.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 280 || Loss: 0.0015 || 10iter: 352.5979 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 137/153 [1:18:52<09:29, 35.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 290 || Loss: 0.0014 || 10iter: 355.5072 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 147/153 [1:24:43<03:24, 34.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "イテレーション 300 || Loss: 0.0014 || 10iter: 350.8640 sec.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 153/153 [1:27:47<00:00, 34.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------\n",
            "epoch 2 || Epoch_TRAIN_Loss:0.0015 ||Epoch_VAL_Loss:0.0000\n",
            "timer:  5267.4561 sec.\n"
          ]
        }
      ],
      "source": [
        "# 学習・検証を実行する\n",
        "num_epochs = 2\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsEvmpMH1-OU"
      },
      "source": [
        "以上"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "4-6_OpenPose_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
